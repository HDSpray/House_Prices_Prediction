{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom sklearn.preprocessing import StandardScaler\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34f227476b9fdf4985fe79af9b031b916af09732"
      },
      "cell_type": "code",
      "source": "train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\nprint(train_data.head())\nprint(test_data.head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "020d4863b128b6b8229fa02cf83af18ea798c53b"
      },
      "cell_type": "markdown",
      "source": "### Preprocessing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72f694b85b987a264370deb7ab45e56174c11b95"
      },
      "cell_type": "code",
      "source": "# Save the 'Id' column\ntrain_Id = train_data['Id']\ntest_Id = test_data['Id']\n\n# drop the Id column\ntrain_data.drop(\"Id\", axis=1, inplace=True)\ntest_data.drop(\"Id\", axis=1, inplace=True)\n\nprint(train_data.shape)\nprint(test_data.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6eeebd75a15722296eca03e4c69ac6b049dfaeae"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e993e528a920ff382baae66e2fc258d927b7545b"
      },
      "cell_type": "code",
      "source": "train_data.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7eb236d7f0c26694d09e92216283a188fa096ba"
      },
      "cell_type": "code",
      "source": "# scatter plot grlivarea/saleprice\nvar = 'GrLivArea'\ndata = pd.concat([train_data['SalePrice'], train_data[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0, 800000));",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "13a65c88a6a8664ad8f97a1c962847787f4fd4f1"
      },
      "cell_type": "code",
      "source": "# Scatter plot totalbsmtsf/saleprice\nvar = \"TotalBsmtSF\"\ndata = pd.concat([train_data['SalePrice'], train_data[var]], axis=1)\ndata.plot.scatter(x=var, y=\"SalePrice\", ylim=(0, 800000));",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "617d98e3081e04bca84f531428a9c4578df06b72"
      },
      "cell_type": "code",
      "source": "#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(train_data[cols], size = 2.5)\nplt.show();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0ae053d3020fdaa54e779a0f9669a02efecf41e4"
      },
      "cell_type": "markdown",
      "source": "### SalePrice"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8772bf98aeeff74cc094abd6f3c177f3df55da36"
      },
      "cell_type": "code",
      "source": "sns.distplot(train_data['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train_data['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train_data['SalePrice'], plot=plt)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34f87744cc0a7454503eaa46afda45bc4a8256c6"
      },
      "cell_type": "code",
      "source": "train_data[\"SalePrice\"] = np.log1p(train_data[\"SalePrice\"])\n\n# Check the new distribution\nsns.distplot(train_data['SalePrice'], fit=norm)\n\n# Get the fitted parmeters used by the function\n(mu, sigma) = norm.fit(train_data['SalePrice'])\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train_data['SalePrice'], plot=plt)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f686a33f940f652a680452b1e9c2cb0d58f075e4"
      },
      "cell_type": "code",
      "source": "ntrain = train_data.shape[0]\nntest = test_data.shape[0]\ny_train = train_data.SalePrice.values\ntrain_data = pd.concat((train_data, test_data)).reset_index(drop=True)\ntrain_data.drop(['SalePrice'], axis=1, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "82490081333b7914d507cd5bf3c7b99701944ce6"
      },
      "cell_type": "markdown",
      "source": "Missing data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33f8875edb62ba81b5dbd1180f69151672141d5d"
      },
      "cell_type": "code",
      "source": "# missing data\ntotal = train_data.isnull().sum().sort_values(ascending=False)\npercent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f7c865ad9e9f0256a3b0447c276c24980cb7f81"
      },
      "cell_type": "code",
      "source": "missing_data_list = list((missing_data[missing_data['Total'] >= 1]).index)\nmissing_data_list.remove(\"LotFrontage\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ff63fede237d78a93e693fdc77c9cf3fee48f657"
      },
      "cell_type": "code",
      "source": "def drop_missing_data(data):\n    for col in missing_data_list:\n        data = data.drop(col, 1)\n    data[\"LotFrontage\"] = data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n        lambda x: x.fillna(x.median()))\n    return data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85b843894d09c38e61ae55a8d7e6df3b8e3d375a"
      },
      "cell_type": "code",
      "source": "train_data = drop_missing_data(train_data)\ntrain_data.isnull().sum().max()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "005a724722a70946de9c0208eb7570e580774dbd"
      },
      "cell_type": "markdown",
      "source": "### dummy variable"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ac888389802de81afcb9a205e2fdf55880748c4"
      },
      "cell_type": "code",
      "source": "train_data = pd.get_dummies(train_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "24922503fa3c7b1b4deaf7c97c557f60db047291"
      },
      "cell_type": "markdown",
      "source": "### seperate data set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55a9cb0a4d0f8195407a87c70d12d5694bab9498"
      },
      "cell_type": "code",
      "source": "test_data = train_data[ntrain:]\ntrain_data = train_data[:ntrain]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fe63decd59b1d9acb25e94613706d11c892e8775"
      },
      "cell_type": "markdown",
      "source": "## Modelling"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8cffce8d3730636d7e645e9af77256b94bb0985b"
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e28db85993607701591ffab40249ebc1989f1ad7"
      },
      "cell_type": "code",
      "source": "# Validation function\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=10).get_n_splits(train_data.values)\n    rmse = np.sqrt(-cross_val_score(model, train_data.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return rmse",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d4ca45d826ecee9b5a7fcbe5d9703e908fb80816"
      },
      "cell_type": "code",
      "source": "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\nscore = rmsle_cv(ENet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dbb59e8ee4a1c39c94a7a8f10456efd757438cdf"
      },
      "cell_type": "code",
      "source": "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\nscore = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d3a5acae73d003d51679f3d81254a825c6ece3ca"
      },
      "cell_type": "code",
      "source": "model_xgb.fit(train_data, y_train)\nxgb_train_pred = model_xgb.predict(train_data)\nxgb_pred = np.expm1(model_xgb.predict(test_data))\nsub = pd.DataFrame()\nsub['Id'] = test_Id\nsub['SalePrice'] = xgb_pred\nsub.to_csv('submission.csv',index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23d998dde4190ded4f068aca70881e0111669a82"
      },
      "cell_type": "code",
      "source": "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\nscore = rmsle_cv(model_lgb)\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}